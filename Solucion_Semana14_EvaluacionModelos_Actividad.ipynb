{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Solucion_Semana14_EvaluacionModelos_Actividad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexher90/An-lisis-de-Datos-2/blob/master/Solucion_Semana14_EvaluacionModelos_Actividad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20IZ09eBzW8c"
      },
      "source": [
        "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
        "\n",
        "\n",
        "# Evaluacion de recomendaciones\n",
        "\n",
        "## Actividad 14\n",
        "\n",
        "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
        "\n",
        "En este cuaderno vamos a estudiar cómo evaluar las recomendaciones que obtenemos de nuestros algoritmos, enfocándonos en la *evaluación de rankings*. AL mismo tiempo, seguiremos trabajndo con los métodos de filtrado colaborativo, centrándonos en los métodos de *Baseline* o de promedios corregidos, de descomposición matricial mediante valores singulares y la factorizacion matricial no-negativa, y de vecindades por los k-vecinos más cercanos.\n",
        "\n",
        "De este modo, la evaluación de los rankings o de las listas de recomendación en base a las primeras N recomendaciones nos permiten evaluar métodos sólo a partir de su output. Sin importar si contamos con ratings explícitos o implícitos, podemos centrarnos en evaluar qué tan acertado es el *ranking* de los items, o esas recomendaciones sobre las que los usuarios toman sus decisiones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IfQHTmmK3DG"
      },
      "source": [
        "**Nombres: Alexander Hernández Páez (200920588), Alexander Camargo (200911325), Juan David Cortés (201728568), Wilson Felipe González (200924943).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QeYEffczW8e"
      },
      "source": [
        "## 1.  Contrucción de algoritmos\n",
        "\n",
        "Podemos evaluar los sistemas de recomendación de acuerdo con el ranking que asignan sobre los items. Entonces nos interesa medir su nivel de acierto sobre un *Top-N* de items. Piense en la lista que ofrece un buscador o en un portal como youtube donde la recomendación de videos es una lista en orden de preferencia.  \n",
        "\n",
        "Puede ver el siguiente video sobre un sistema de recomendacion de este tipo en Amazon: https://www.youtube.com/watch?v=EeXBdQYs0CQ\n",
        "\n",
        "A continuación veamos algunos ejemplos sobre las recomendaciones que se pueden hacer en forma de ranking de preferencias. \n",
        "\n",
        "Finalmente, si quiere investigar sobre cómo calcular diferentes métricas como Precision@k and Recall@k, puede ver: https://surprise.readthedocs.io/en/stable/FAQ.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFY5WC9VzW8e"
      },
      "source": [
        "Implementemos una función `Top_N` que recibe las predicciones del sistema, el numero de recomendaciones a ofrecer y el rating mínimo a tener en cuenta.\n",
        "\n",
        "A continuación entrenemos un algoritmo *BaselineOnly* que ofrezca las 10 mejores recomendaciones para cada usuario.\n",
        "\n",
        "Primero importemos las bibliotecas y funciones que vamos a utilizar:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPmFUZjezmIp",
        "outputId": "5a2c1ac7-fc84-4498-e2d2-6f2ab6b0fd8e"
      },
      "source": [
        "pip install surprise"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Using cached https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "  Using cached https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1670957 sha256=9a10d2642d30f268dc4c1a11be187c82e9ffc2e6759862bfefb54410c9018deb\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNLQ1CBGzW8e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import Reader, Dataset, BaselineOnly, accuracy\n",
        "from surprise.model_selection import LeaveOneOut, train_test_split\n",
        "from collections import defaultdict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhZpEZ9tzW8g"
      },
      "source": [
        "Carguemos los datos de las películas y las preferencias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i-Vr2XOzW8h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "c47af96f-488f-4744-9177-b87b41714615"
      },
      "source": [
        "pelis = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
        "\n",
        "df = pd.read_csv('ratings_small.csv')\n",
        "df.drop(['timestamp'], axis=1, inplace=True)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1029</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1061</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1129</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1172</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>671</td>\n",
              "      <td>6268</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100000</th>\n",
              "      <td>671</td>\n",
              "      <td>6269</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>671</td>\n",
              "      <td>6365</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100002</th>\n",
              "      <td>671</td>\n",
              "      <td>6385</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100003</th>\n",
              "      <td>671</td>\n",
              "      <td>6565</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100004 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        userId  movieId  rating\n",
              "0            1       31     2.5\n",
              "1            1     1029     3.0\n",
              "2            1     1061     3.0\n",
              "3            1     1129     2.0\n",
              "4            1     1172     4.0\n",
              "...        ...      ...     ...\n",
              "99999      671     6268     2.5\n",
              "100000     671     6269     4.0\n",
              "100001     671     6365     4.0\n",
              "100002     671     6385     2.5\n",
              "100003     671     6565     3.5\n",
              "\n",
              "[100004 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMHSaiznzW8h"
      },
      "source": [
        "Veamos las preferencias por usuario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "oyKlewMizW8h",
        "outputId": "c8fb0904-8bc2-4dbb-f713-13df37100fb4"
      },
      "source": [
        "df[df['userId'] == 2]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>2</td>\n",
              "      <td>592</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>2</td>\n",
              "      <td>593</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>2</td>\n",
              "      <td>616</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>2</td>\n",
              "      <td>661</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2</td>\n",
              "      <td>720</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    userId  movieId  rating\n",
              "20       2       10     4.0\n",
              "21       2       17     5.0\n",
              "22       2       39     5.0\n",
              "23       2       47     4.0\n",
              "24       2       50     4.0\n",
              "..     ...      ...     ...\n",
              "91       2      592     5.0\n",
              "92       2      593     3.0\n",
              "93       2      616     3.0\n",
              "94       2      661     4.0\n",
              "95       2      720     4.0\n",
              "\n",
              "[76 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xoW58O4zW8h"
      },
      "source": [
        "Filtremos los datos para quedarnos con los usuarios y peliculas con un mínimo de entradas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2pvTl1EzW8i",
        "outputId": "a527741d-17b6-47e8-b42f-38938da19622"
      },
      "source": [
        "min_p_ratings = 5\n",
        "filter_p = df['movieId'].value_counts() > min_p_ratings\n",
        "filter_p = filter_p[filter_p].index.tolist()\n",
        "\n",
        "min_u_ratings = 30\n",
        "filter_u = df['userId'].value_counts() > min_u_ratings\n",
        "filter_u = filter_u[filter_u].index.tolist()\n",
        "\n",
        "df_nuevo = df[(df['movieId'].isin(filter_p)) & (df['userId'].isin(filter_u))]\n",
        "print('Los datos originales tienen tamaño:\\t{}'.format(df.shape))\n",
        "print('Los nuevo datos tienen tamaño:\\t{}'.format(df_nuevo.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los datos originales tienen tamaño:\t(100004, 3)\n",
            "Los nuevo datos tienen tamaño:\t(85239, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQphnHSczW8i"
      },
      "source": [
        "Declaremos los datos para trabajarlos con SurPRISE:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIUIr73PzW8i",
        "outputId": "e330fb99-840a-4201-8519-67cddcc2d913"
      },
      "source": [
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(df_nuevo[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.dataset.DatasetAutoFolds at 0x7f4f2e8b9160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHvpMlIjzW8j"
      },
      "source": [
        "Especifiquemos las opciones para la implementacion del algoritmo del *BaselineOnly*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWYSUlnfzW8j"
      },
      "source": [
        "bsl_options = {'method': 'als',\n",
        "               'n_epochs': 20,\n",
        "               'reg_u': 12, \n",
        "               'reg_i': 5  \n",
        "               }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCVBUl93zW8j"
      },
      "source": [
        "Podemos entrenar el algoritmo sobre el 75% de los datos con rating observado y lo probamos sobre la muestra sobrante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfBFAMwpzW8j",
        "outputId": "b0446ccf-e39b-4ccc-f707-130066dbd13c"
      },
      "source": [
        "trainSet, testSet = train_test_split(data, test_size=.25, random_state=0)\n",
        "algoritmo = BaselineOnly(bsl_options=bsl_options)\n",
        "algoritmo.fit(trainSet)\n",
        "preds = algoritmo.test(testSet)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pNH36byzW8j"
      },
      "source": [
        "O podemos construirlo mediante validacion cruzada. Exploremos el uso del LOOCV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT6PQoaszW8j",
        "outputId": "df5a5b75-ea83-4a14-8a01-bf97b2994743"
      },
      "source": [
        "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "algoritmo2 = BaselineOnly(bsl_options=bsl_options)\n",
        "\n",
        "for trainSet, testSet in LOOCV.split(data):\n",
        "    # Entrenamos el modelo en entrenamiento\n",
        "    algoritmo2.fit(trainSet)\n",
        "    # Predecimos\n",
        "    predV = algoritmo2.test(testSet)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEYXYoCzW8k"
      },
      "source": [
        "### Pregunta 1\n",
        "\n",
        "Cuál es el RMSE resultante según el método de construcción del algoritmo del BaselineOnly?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6apAN-7caQL"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql862WOkzW8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96814c08-e4d3-4b0c-af23-eaee46d87ac1"
      },
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.3)\n",
        "Base = BaselineOnly(bsl_options=bsl_options)\n",
        "\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nTermina: ', tiempo)\n",
        "\n",
        "print(\"\\nBaselineOnly: \")\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nInicia el entrenamiento y prueba: ', tiempo)\n",
        "\n",
        "predBase = Base.fit(trainset).test(testset)\n",
        "print(\"\\nRMSE del BaselineOnly: \", accuracy.rmse(predBase))\n",
        "\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nTermina: ', tiempo)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Termina:  2020-11-29 23:29:26.073200\n",
            "\n",
            "BaselineOnly: \n",
            "\n",
            "Inicia el entrenamiento y prueba:  2020-11-29 23:29:26.074108\n",
            "Estimating biases using als...\n",
            "RMSE: 0.8753\n",
            "\n",
            "RMSE del BaselineOnly:  0.8753021305904519\n",
            "\n",
            "Termina:  2020-11-29 23:29:26.492061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnSbZDe7zW8k"
      },
      "source": [
        "### Ejercicio 2\n",
        "\n",
        "Encuentre un algoritmo distinto con resultados al menos tan buenos como los obtenidos por el *BaselineOnly*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbK2evLgj9qV"
      },
      "source": [
        "import surprise\n",
        "from surprise import Reader\n",
        "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import LeaveOneOut"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRokpptIzW8k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc927be0-81b1-4cc4-c140-03f73ae90d05"
      },
      "source": [
        "benchmark = []\n",
        "# Iterate over all algorithms\n",
        "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
        "    # Perform cross validation\n",
        "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=10, verbose=False)\n",
        "    \n",
        "    # Get results & append algorithm name\n",
        "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
        "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
        "    benchmark.append(tmp)\n",
        "    \n",
        "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n",
            "Estimating biases using als...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_rmse</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>test_time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Algorithm</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVDpp</th>\n",
              "      <td>0.856090</td>\n",
              "      <td>341.718077</td>\n",
              "      <td>3.287392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNNBaseline</th>\n",
              "      <td>0.861302</td>\n",
              "      <td>0.346738</td>\n",
              "      <td>1.082578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVD</th>\n",
              "      <td>0.869999</td>\n",
              "      <td>5.008862</td>\n",
              "      <td>0.066101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaselineOnly</th>\n",
              "      <td>0.871546</td>\n",
              "      <td>0.217571</td>\n",
              "      <td>0.061418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNNWithZScore</th>\n",
              "      <td>0.874141</td>\n",
              "      <td>0.205626</td>\n",
              "      <td>0.956659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNNWithMeans</th>\n",
              "      <td>0.876058</td>\n",
              "      <td>0.160673</td>\n",
              "      <td>0.884197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SlopeOne</th>\n",
              "      <td>0.882668</td>\n",
              "      <td>1.812730</td>\n",
              "      <td>2.611692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NMF</th>\n",
              "      <td>0.901271</td>\n",
              "      <td>5.183552</td>\n",
              "      <td>0.067285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNNBasic</th>\n",
              "      <td>0.921880</td>\n",
              "      <td>0.140622</td>\n",
              "      <td>0.830761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CoClustering</th>\n",
              "      <td>0.922729</td>\n",
              "      <td>1.702901</td>\n",
              "      <td>0.064819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NormalPredictor</th>\n",
              "      <td>1.420198</td>\n",
              "      <td>0.120873</td>\n",
              "      <td>0.083926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 test_rmse    fit_time  test_time\n",
              "Algorithm                                        \n",
              "SVDpp             0.856090  341.718077   3.287392\n",
              "KNNBaseline       0.861302    0.346738   1.082578\n",
              "SVD               0.869999    5.008862   0.066101\n",
              "BaselineOnly      0.871546    0.217571   0.061418\n",
              "KNNWithZScore     0.874141    0.205626   0.956659\n",
              "KNNWithMeans      0.876058    0.160673   0.884197\n",
              "SlopeOne          0.882668    1.812730   2.611692\n",
              "NMF               0.901271    5.183552   0.067285\n",
              "KNNBasic          0.921880    0.140622   0.830761\n",
              "CoClustering      0.922729    1.702901   0.064819\n",
              "NormalPredictor   1.420198    0.120873   0.083926"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4BFssjyyf5s"
      },
      "source": [
        "**De acuerdo con los resultados del modelo anterior, podemos ver que el modelo SVDpp fue el que tuvo el mejor rendimiento en términos del RMSE. Adicionalmente, podemos ver que los modelos KKNBaseline y SVD tuvieron un mejor rendimiento que el Baseline Only.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKJlVfWIzW8k"
      },
      "source": [
        "## 2. Evaluacion de rankings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlKpw9U_zW8k"
      },
      "source": [
        "Construyamos una función para quedarnos con las N recomendaciones más atractivas para cada usuario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL8ryGiozW8k"
      },
      "source": [
        "def Top_N(preds, N, min_r):\n",
        "    topN = defaultdict(list)\n",
        "    for uid, iid, r_ui, est, _ in preds:\n",
        "        if (est >= min_r):\n",
        "            topN[int(uid)].append((int(iid), est))\n",
        "\n",
        "    for uid, ratings in topN.items():\n",
        "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        topN[int(uid)] = ratings[:N]\n",
        "\n",
        "    return topN"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1EA6J_dzW8k"
      },
      "source": [
        "Veamos qué tan bien le va a nuestro algoritmo del *BaselineOnly*. La siguiente celda toma el conjunto de entrenamiento de la implementacion del LOOCV y predice para los ratings sobrantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPMuprdjzW8l"
      },
      "source": [
        "# Obtenemos las predicciones que no están en entrenamiento\n",
        "X_Prueba = trainSet.build_anti_testset() #observaciones sin rating\n",
        "Preds_T = algoritmo.test(X_Prueba)\n",
        "# Calculamos las I recomendaciones para cada usuario\n",
        "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z79STVhYzW8l"
      },
      "source": [
        "Veamos las recomendaciones para un usuario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUIp-RJwzW8l",
        "outputId": "3c529305-0d51-49c8-86cf-130e6635dce3"
      },
      "source": [
        "#topN_pred.keys()\n",
        "usuario=40\n",
        "topN_pred[usuario]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(969, 4.829882881081904),\n",
              " (318, 4.814097149422216),\n",
              " (3462, 4.778969585834668),\n",
              " (1221, 4.755216895401907),\n",
              " (858, 4.740759357195653),\n",
              " (3088, 4.719898252433616),\n",
              " (1172, 4.675544584905746),\n",
              " (1193, 4.66348839144212),\n",
              " (923, 4.6603933676684655),\n",
              " (1945, 4.658622202021493)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIcBjbEfzW8l"
      },
      "source": [
        "Veamos los titulos de las peliculas que tenemos en nuestra base original (pelis):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6dj8brPzW8m",
        "outputId": "e131e4d4-aabb-4466-8b9f-134f6532d4ad"
      },
      "source": [
        "for i in range(10):\n",
        "    print(np.squeeze(pelis[pelis.id == str(topN_pred[usuario][i][0])]['original_title']))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Series([], Name: original_title, dtype: object)\n",
            "The Million Dollar Hotel\n",
            "Series([], Name: original_title, dtype: object)\n",
            "Series([], Name: original_title, dtype: object)\n",
            "Sleepless in Seattle\n",
            "My Darling Clementine\n",
            "Series([], Name: original_title, dtype: object)\n",
            "Series([], Name: original_title, dtype: object)\n",
            "Dawn of the Dead\n",
            "Nell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0oW6RqszW8m"
      },
      "source": [
        "### 2.1 Tasa de aciertos\n",
        "\n",
        "Para evaluar nuestro recomendador, vemos la tasa de acierto. Esto es, si un usuario calificó entre sus primeras N preferencias una de las peliculas recomendadas, entonces lo consideramos un acierto.\n",
        "\n",
        "Entonces computamos la tasa de acierto para cada usuario:\n",
        "\n",
        "- Encontramos todos los items en la historia del usuario en los datos de entrenamiento.\n",
        "- Quitamos uno de esos items (algo como *Leave-One-Out cross-validation*).\n",
        "- Usamos los demás items para entrenar el recomendador y pedimos las N recomendaciones.\n",
        "- Si el item que dejamos fuera aparece en las top-N recomendaciones entonces lo consideramos un acierto. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX6W9ZR4zW8m",
        "outputId": "2cf42474-5851-4c7d-c954-acca2ec3aeff"
      },
      "source": [
        "def TasaAcierto(topN_pred, predV):\n",
        "    aciertos = 0\n",
        "    total = 0\n",
        "\n",
        " # Para cada observacion dejada por fuera\n",
        "    for obs_out in predV:\n",
        "        userID = obs_out[0]\n",
        "        movieID_V = obs_out[1]\n",
        "        # Verficamos si se encuentra en el top-N\n",
        "        acierto = False\n",
        "        for movieID, predRating in topN_pred[int(userID)]:\n",
        "            if (int(movieID_V) == int(movieID)):\n",
        "                acierto = True\n",
        "                break\n",
        "        if (acierto) :\n",
        "            aciertos += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    # Calculamos la tasa de aciertos\n",
        "    return aciertos/total\n",
        "print(\"\\nTasa de aciertos: \", TasaAcierto(topN_pred, predV))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tasa de aciertos:  0.020146520146520148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzFqUCzOzW8m"
      },
      "source": [
        "Deseariamos que la tasa fuera más alta. Los resultados se pueden deber a que no contamos con suficientes datos para todos los usuarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5X1DDGZzW8m"
      },
      "source": [
        "### 2.2 Tasa de aciertos por nivel de rating\n",
        "\n",
        "También podemos discriminar por niveles del rating:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1J_KGpLzW8m",
        "outputId": "ef8bc8ca-dca7-4cf7-c184-6947da1f3abb"
      },
      "source": [
        "def TasaAcierto_R(topN_pred, predV):\n",
        "    aciertos = defaultdict(float)\n",
        "    total = defaultdict(float)\n",
        "    # Para cada rating por fuera de la muestra\n",
        "    for userID, movieID_V, ratings, est_r, _ in predV:\n",
        "        # Verficamos si se encuentra en el top-N\n",
        "        acierto = False\n",
        "        for movieID, pred_r in topN_pred[int(userID)]:\n",
        "            if (int(movieID_V) == movieID):\n",
        "                acierto = True\n",
        "                break\n",
        "        if (acierto) :\n",
        "            aciertos[ratings] += 1\n",
        "        total[ratings] += 1\n",
        "\n",
        "    # Calculamos la tasa de aciertos\n",
        "    for rating in sorted(aciertos.keys()):\n",
        "        print(rating, aciertos[rating] / total[rating])\n",
        "print(\"Tasa de aciertos por nivel de rating: \")\n",
        "TasaAcierto_R(topN_pred, predV)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tasa de aciertos por nivel de rating: \n",
            "3.5 0.020833333333333332\n",
            "4.0 0.012345679012345678\n",
            "4.5 0.022222222222222223\n",
            "5.0 0.06666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdyQSSh9zW8m"
      },
      "source": [
        "La tasa mejora para ratings de 5, lo cual es una buena señal pues nos interesa que el sistema acierte más con las peliculas que los usuarios más prefieren.\n",
        "\n",
        "### 2.3 Tasa de acierto acumulativa\n",
        "\n",
        "Calculemos la tasa de acierto para ratings mayores que 4.0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qm_7-BZzW8m",
        "outputId": "22823e5b-b419-4b81-ba0e-2ab1f7e0ced8"
      },
      "source": [
        "def TasaAcierto_Acum(topN_pred, predV, umbral):\n",
        "    aciertos = 0\n",
        "    total = 0\n",
        "    # Para cada rating por fuera de la muestra\n",
        "    for userID, movieID_V, ratings, est_r, _ in predV:\n",
        "        # Nos fijamos solo en lo que los usuarios prefieren más\n",
        "        if (ratings >= umbral):\n",
        "            # Verficamos si se encuentra en el top-N\n",
        "            acierto = False\n",
        "            for movieID, pred_r in topN_pred[int(userID)]:\n",
        "                if (int(movieID_V) == movieID):\n",
        "                    acierto = True\n",
        "                    break\n",
        "            if (acierto) :\n",
        "                aciertos += 1\n",
        "            total += 1\n",
        "\n",
        "        # Calculamos la precision global\n",
        "    return aciertos/total\n",
        "print(\"Tasa de aciertos acumulada (rating >= 4): \", \n",
        "      TasaAcierto_Acum(topN_pred, predV, 4.0))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tasa de aciertos acumulada (rating >= 4):  0.03205128205128205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uWDY6ALzW8m"
      },
      "source": [
        "### 2.4 Tasa de aciertos promedio recíproca \n",
        "\n",
        "Otra metrica relevante es la tasa de aciertos promedio recíproca.\n",
        "\n",
        "Tomamos en cuenta donde ocurre el primer resultado relevante. Es decir, si la primera recomendación pertenece al primer lugar la tasa recíproca es de 1; si aparece en segundo lugar es de 1/2; en tercer lugar es de 1/3; etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbARlN5bzW8n",
        "outputId": "03de4bd8-e73e-4163-dfa6-f587c279a88a"
      },
      "source": [
        "def TasaAcierto_Recip(topN_pred, predV):\n",
        "    suma = 0\n",
        "    total = 0\n",
        "    # Para cada rating por fuera de la muestra\n",
        "    for userID, movieID_V, ratings, est_r, _ in predV:\n",
        "        # Verficamos si se encuentra en el top-N\n",
        "        aciertoRank = 0\n",
        "        rank = 0\n",
        "        for movieID, pred_r in topN_pred[int(userID)]:\n",
        "            rank = rank + 1\n",
        "            if (int(movieID_V) == movieID):\n",
        "                aciertoRank = rank\n",
        "                break\n",
        "        if (aciertoRank > 0) :\n",
        "                suma += 1.0 / aciertoRank\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return suma / total\n",
        "\n",
        "print(\"Tasa reciproca media de aciertos : \", \n",
        "      TasaAcierto_Recip(topN_pred, predV,))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tasa reciproca media de aciertos :  0.00572562358276644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWNS8fCvzW8n"
      },
      "source": [
        "Una tasa reciproca media de aciertos de 0.0057 nos dice que en promedio la tasa reciproca es de 1/133. De nuevo, este valor tan bajo se puede deber a que en muchos casos el algoritmo simplemente no logra recomendar las peliculas más preferidas de ciertos usuarios con poca información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpP2yFzvzW8n"
      },
      "source": [
        "### Ejercicio 3\n",
        "\n",
        "Evalúe su algoritmo propuesto en el Ejercicio 2 de acuerdo con la tasa de aciertos promedio recíproca. Analice si su algoritmo mejora las recomendaciones del BaselineOnly. El grupo que logre la mejor tasa se ganará un bono en las Actividades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDAzThEWzW8n"
      },
      "source": [
        "bsl_options = {'method': 'als',\n",
        "               'n_epochs': 20,\n",
        "               'reg_u': 12, \n",
        "               'reg_i': 5  \n",
        "               }\n",
        "\n",
        "sim_options = {'name': 'pearson_baseline',\n",
        "               'user_based': False  # calcula similitudes entre items\n",
        "               }"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7CGQMr4Gz8",
        "outputId": "9c932a62-0283-4f49-e94c-dfeda1931f27"
      },
      "source": [
        "SVD = SVDpp(random_state=0)\n",
        "\n",
        "print(\"\\nSVDpp: \")\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nInicia el entrenamiento y prueba: ', tiempo)\n",
        "\n",
        "predSVD = SVD.fit(trainset).test(testset)\n",
        "print(\"RMSE del SVDpp: \", accuracy.rmse(predSVD))\n",
        "\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nTermina: ', tiempo)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SVDpp: \n",
            "\n",
            "Inicia el entrenamiento y prueba:  2020-11-30 02:21:59.414990\n",
            "RMSE: 0.8689\n",
            "RMSE del SVDpp:  0.8689042285037836\n",
            "\n",
            "Termina:  2020-11-30 02:25:36.038776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjamXpcs5Ntl"
      },
      "source": [
        "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
        "algoritmo = SVD\n",
        "algoritmo.fit(trainset)\n",
        "preds = algoritmo.test(testset)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnAj_6mO7FXf"
      },
      "source": [
        "# Obtenemos las predicciones que no están en entrenamiento\n",
        "X_Prueba = trainset.build_anti_testset() #observaciones sin rating\n",
        "Preds_T = algoritmo.test(X_Prueba)\n",
        "# Calculamos las I recomendaciones para cada usuario\n",
        "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-C6g6iX6F8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614e009a-df00-4079-fb61-4e398455d3b4"
      },
      "source": [
        "def TasaAcierto_Recip(topN_pred, predSVD):\n",
        "    suma = 0\n",
        "    total = 0\n",
        "    # Para cada rating por fuera de la muestra\n",
        "    for userID, movieID_V, ratings, est_r, _ in predSVD:\n",
        "        # Verficamos si se encuentra en el top-N\n",
        "        aciertoRank = 0\n",
        "        rank = 0\n",
        "        for movieID, pred_r in topN_pred[int(userID)]:\n",
        "            rank = rank + 1\n",
        "            if (int(movieID_V) == movieID):\n",
        "                aciertoRank = rank\n",
        "                break\n",
        "        if (aciertoRank > 0) :\n",
        "                suma += 1.0 / aciertoRank\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return suma / total\n",
        "\n",
        "print(\"Tasa reciproca media de aciertos : \", \n",
        "      TasaAcierto_Recip(topN_pred, predSVD,))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tasa reciproca media de aciertos :  0.0016631068455329374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAIlIKY-8NXV"
      },
      "source": [
        "**El grupo de trabajo implementó el algoritmo de factor latente SVD, el cual fue el algoritmo que mejor tuvo rendimiento en el ejercicio anterior. Sin embargo, este no mejoró la Tasa de Aciertos Promedio Recíproca, por lo que fue necesario implementar el modelo variando el algoritmo como se muestra a continuación:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj1yQ17aJVn-"
      },
      "source": [
        "**Modelo con KNN Baseline:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5pZTGfW8jEG"
      },
      "source": [
        "bsl_options = {'method': 'als',\n",
        "               'n_epochs': 20,\n",
        "               'reg_u': 50, \n",
        "               'reg_i': 35  \n",
        "               }\n",
        "\n",
        "sim_options = {'name': 'pearson_baseline',\n",
        "               'user_based': False  # calcula similitudes entre items\n",
        "               }"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFAo5vQ08jEG",
        "outputId": "b43058c8-74f4-4264-9dfa-44e726078852"
      },
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.3)\n",
        "\n",
        "KNN = KNNBaseline(bsl_options=bsl_options, sim_options=sim_options)\n",
        "Base = KNNBaseline(k=51, bsl_options=bsl_options)\n",
        "\n",
        "print(\"\\nKNNBaseline: \")\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nInicia el entrenamiento y prueba: ', tiempo)\n",
        "\n",
        "predKNN = KNN.fit(trainset).test(testset)\n",
        "print(\"\\nFCP del KNNBaseline: \", accuracy.rmse(predKNN))\n",
        "\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nTermina: ', tiempo)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "KNNBaseline: \n",
            "\n",
            "Inicia el entrenamiento y prueba:  2020-11-30 03:02:33.797685\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.8703\n",
            "\n",
            "FCP del KNNBaseline:  0.8703443780272654\n",
            "\n",
            "Termina:  2020-11-30 03:02:45.346987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xBwjK_K8jEH",
        "outputId": "2fd51ccb-8083-4d7d-bd6a-ccf1fa851d89"
      },
      "source": [
        "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
        "algoritmo = KNN\n",
        "algoritmo.fit(trainset)\n",
        "preds = algoritmo.test(testset)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV2sMDl88jEH"
      },
      "source": [
        "# Obtenemos las predicciones que no están en entrenamiento\n",
        "X_Prueba = trainset.build_anti_testset() #observaciones sin rating\n",
        "Preds_T = algoritmo.test(X_Prueba)\n",
        "# Calculamos las I recomendaciones para cada usuario\n",
        "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T5asx_78jEH",
        "outputId": "2ccdba17-531a-4f88-91b7-a11e5290ce7f"
      },
      "source": [
        "def TasaAcierto_Recip(topN_pred, predKNN):\n",
        "    suma = 0\n",
        "    total = 0\n",
        "    # Para cada rating por fuera de la muestra\n",
        "    for userID, movieID_V, ratings, est_r, _ in predKNN:\n",
        "        # Verficamos si se encuentra en el top-Nd\n",
        "        aciertoRank = 0\n",
        "        rank = 0\n",
        "        for movieID, pred_r in topN_pred[int(userID)]:\n",
        "            rank = rank + 1\n",
        "            if (int(movieID_V) == movieID):\n",
        "                aciertoRank = rank\n",
        "                break\n",
        "        if (aciertoRank > 0) :\n",
        "                suma += 1.0 / aciertoRank\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return suma / total\n",
        "\n",
        "print(\"Tasa reciproca media de aciertos : \", \n",
        "      TasaAcierto_Recip(topN_pred, predKNN,))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tasa reciproca media de aciertos :  0.0018019150410046726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjwjlKmbJnbU"
      },
      "source": [
        "**Al no haber obtenido un resultado significativamente mejor que el anterior modelo, el grupo de trabajo recurrió a implementarlo por medio del algoritmo Baseline Only, manteniendo los parámetros del modelo anterior:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB2l-HO3J4k8"
      },
      "source": [
        "**Prueba con Baseline Only:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yrfKGMrCy6H"
      },
      "source": [
        "import surprise\n",
        "\n",
        "from surprise import Reader\n",
        "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import LeaveOneOut"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s42y3Q3YC1OV"
      },
      "source": [
        "bsl_options = {'method': 'als',\n",
        "               'n_epochs': 20,\n",
        "               'reg_u': 50, \n",
        "               'reg_i': 35  \n",
        "               }\n",
        "\n",
        "sim_options = {'name': 'pearson_baseline',\n",
        "               'user_based': False  # calcula similitudes entre items\n",
        "               }"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBcwBrDVC1OV",
        "outputId": "35ca86f7-0f35-4bcd-d7a3-e2323f633716"
      },
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.3)\n",
        "\n",
        "print(\"\\nBaselineOnly: \")\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nInicia el entrenamiento y prueba: ', tiempo)\n",
        "\n",
        "predBase = BaselineOnly(bsl_options=bsl_options)\n",
        "Base.fit(trainset).test(testset)\n",
        "#print(\"\\nRMSE del BaselineOnly: \", accuracy.rmse(predBase))\n",
        "\n",
        "tiempo = datetime.datetime.now()\n",
        "print('\\nTermina: ', tiempo)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BaselineOnly: \n",
            "\n",
            "Inicia el entrenamiento y prueba:  2020-11-30 03:07:48.714756\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "\n",
            "Termina:  2020-11-30 03:07:52.025432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIBoPbUFC1OW"
      },
      "source": [
        "# Obtenemos las predicciones que no están en entrenamiento\n",
        "X_Prueba = trainset.build_anti_testset() #observaciones sin rating\n",
        "Preds_T = algoritmo.test(X_Prueba)\n",
        "# Calculamos las I recomendaciones para cada usuario\n",
        "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW4EY2P1C1OW",
        "outputId": "931160ab-2c2b-410e-f169-29e5e80d8090"
      },
      "source": [
        "def TasaAcierto_Recip(topN_pred, predKNN):\n",
        "    suma = 0\n",
        "    total = 0\n",
        "    # Para cada rating por fuera de la muestra\n",
        "    for userID, movieID_V, ratings, est_r, _ in predKNN:\n",
        "        # Verficamos si se encuentra en el top-Nd\n",
        "        aciertoRank = 0\n",
        "        rank = 0\n",
        "        for movieID, pred_r in topN_pred[int(userID)]:\n",
        "            rank = rank + 1\n",
        "            if (int(movieID_V) == movieID):\n",
        "                aciertoRank = rank\n",
        "                break\n",
        "        if (aciertoRank > 0) :\n",
        "                suma += 1.0 / aciertoRank\n",
        "\n",
        "        total += 1\n",
        "\n",
        "    return suma / total\n",
        "\n",
        "print(\"Tasa reciproca media de aciertos : \", \n",
        "      TasaAcierto_Recip(topN_pred, predKNN,))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tasa reciproca media de aciertos :  0.006775112412137279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KesKLXMNKAF-"
      },
      "source": [
        "**Según el resultado anterior, podemos evidenciar que con el modelo probado con BaseLine Only, el resultado de la Tasa de Aciertos Promedio Recíproca crece significativamente, superando el índice inicial de 0.0057, siendo éste en 0.0067.**"
      ]
    }
  ]
}